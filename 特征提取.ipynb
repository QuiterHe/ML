{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "## 分类变量特征提取\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "onehot_encoder = DictVectorizer()\n",
    "instances = [{'city': 'Beijing'},{'city': 'Shanghai'},{'city': 'Chongqing'}, {'city': 'Beijing'},]\n",
    "print(onehot_encoder.fit_transform(instances).toarray())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 1 0 1 0 0 1]\n",
      " [0 1 1 1 0 1 0 0 1 0]\n",
      " [1 0 0 0 0 0 0 1 0 0]]\n",
      "{u'duke': 2, u'basketball': 1, u'lost': 5, u'played': 6, u'in': 4, u'game': 3, u'unc': 9, u'ate': 0, u'the': 8, u'sanwich': 7}\n"
     ]
    }
   ],
   "source": [
    "## 文字特征提取\n",
    "### 词库表示法\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'UNC played Duke in basketball',\n",
    "    'Duke lost the basketball game',\n",
    "    'I ate a sanwich'\n",
    "]\n",
    "\n",
    "# corpus（文集）由两个文档组成，构成的词库表vocabulary包括8个词\n",
    "# UNC, played, Duke, in, basketball, lost, the, game\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "print(vectorizer.fit_transform(corpus).todense())\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用文档特征向量间的欧式距离表示文档间的相似度\n",
    "$$ d = \\| x_0 - x_1 \\| $$\n",
    "向量的\n",
    "$$ \\| x \\| = \\sqrt{x_1^2 + x_2^2 + \\cdots + x_n^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文档0与文档1的距离[[ 2.44948974]]\n",
      "文档0与文档2的距离[[ 2.64575131]]\n",
      "文档1与文档2的距离[[ 2.64575131]]\n"
     ]
    }
   ],
   "source": [
    "## 用欧式距离表示文档的相似度\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'UNC played Duke in basketball',\n",
    "    'Duke lost the basketball game',\n",
    "    'I ate a sanwich'\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "counts = vectorizer.fit_transform(corpus).todense()\n",
    "for x,y in [[0, 1], [0, 2], [1, 2]]:\n",
    "    dist = euclidean_distances(counts[x], counts[y])\n",
    "    print('文档{}与文档{}的距离{}'.format(x, y, dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现实中的新闻报告组成的文集，其中词汇表维度成千上万。但是是一个巨大的稀疏矩阵。\n",
    "高维数据会导致如下问题：\n",
    "> 1. 占用更大的内存\n",
    "> 2. 维度灾难(高维数据需要更多的训练数据，数据不足时会导致过拟合)\n",
    "\n",
    "所以，需要对高维数据进行降维\n",
    "常用的一些降维手段有（针对文本处理）：\n",
    "> 1. 将单词全部转换为小写\n",
    "> 2. 停用词（文集常用词）\n",
    "> 3. 词根还原和词形还原（将单词从不同的时态、派生形式还原）\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
